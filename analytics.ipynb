{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import eikon as ek\n",
    "import random\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random test data for the attribution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_portfolio_data(start_date, tickers, sector_map, common_data=None, num_days=20):\n",
    "    dates = [start_date + timedelta(days=i) for i in range(num_days)]\n",
    "    data = []\n",
    "\n",
    "    for date in dates:\n",
    "        daily_weights = np.random.dirichlet(np.ones(len(tickers)), size=1).flatten()\n",
    "        for ticker, weight in zip(tickers, daily_weights):\n",
    "            # Use pre-generated returns for common tickers\n",
    "            if common_data and ticker in common_data['returns']:\n",
    "                return_ = common_data['returns'][ticker].loc[common_data['returns'][ticker]['Date'] == date]['Return'].values[0]\n",
    "            else:\n",
    "                return_ = np.random.uniform(-0.05, 0.05)\n",
    "            # Use the pre-assigned GICS Sector\n",
    "            gics_sector = sector_map[ticker]\n",
    "            data.append([date, ticker, weight, return_, gics_sector])\n",
    "\n",
    "    return pd.DataFrame(data, columns=['Date', 'Ticker', 'Weight', 'Return', 'GICS Sector'])\n",
    "\n",
    "# Define all possible tickers and assign GICS Sectors. Note that this data is completely random and nonsensical used for tests only.\n",
    "all_tickers = ['AAPL', 'TSLA', 'NVDA', 'GOOGL', 'FB', 'JNJ', 'PG', 'V']\n",
    "gics_sectors = ['Information Technology', 'Consumer Discretionary', 'Health Care', 'Financials', 'Industrials']\n",
    "\n",
    "# Create a persistent mapping of tickers to GICS Sectors\n",
    "sector_map = {ticker: random.choice(gics_sectors) for ticker in all_tickers}\n",
    "\n",
    "# Generate common returns for the common tickers\n",
    "num_days = 20\n",
    "dates = [datetime(2023, 9, 1) + timedelta(days=i) for i in range(num_days)]\n",
    "common_returns_data = {\n",
    "    ticker: pd.DataFrame({'Date': dates, 'Return': np.random.uniform(-0.05, 0.05, num_days)})\n",
    "    for ticker in all_tickers if ticker in ['TSLA', 'NVDA']  # Common tickers\n",
    "}\n",
    "common_data = {'returns': common_returns_data}\n",
    "\n",
    "# Define the contents of each portfolio\n",
    "tickers_portfolio_1 = ['AAPL', 'TSLA', 'NVDA', 'GOOGL', 'FB']\n",
    "tickers_portfolio_2 = ['TSLA', 'NVDA', 'JNJ', 'PG', 'V']\n",
    "\n",
    "# Create two datasets for the same month with some common tickers\n",
    "portfolio_1 = create_portfolio_data(datetime(2023, 9, 1), tickers_portfolio_1, sector_map, common_data=common_data, num_days=num_days)\n",
    "portfolio_2 = create_portfolio_data(datetime(2023, 9, 1), tickers_portfolio_2, sector_map, common_data=common_data, num_days=num_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_dataframes(df1, df2):\n",
    "    merged_data = (pd.merge(df1, df2, on=['Date', 'Ticker', 'GICS Sector', 'Return'], how='outer', suffixes=('_portofolio', '_benchmark'))\n",
    "                     .rename(columns={'Weight_portofolio': 'Portfolio Weight', 'Weight_benchmark': 'Benchmark Weight'})\n",
    "                     .fillna(0)\n",
    "                   )\n",
    "    return merged_data\n",
    "\n",
    "merged_data = merge_dataframes(portfolio_1, portfolio_2)\n",
    "merged_data.sort_values(by=['Date', 'Ticker'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_returns(weights, returns):\n",
    "    return weights * returns\n",
    "\n",
    "def calculate_sector_weights(df, weight_column_name):\n",
    "    return df.groupby(['Date', 'GICS Sector'])[weight_column_name].transform('sum')\n",
    "\n",
    "# Function to calculate asset weight in sector\n",
    "def calculate_asset_weight_in_sector(df, weight_column_name):\n",
    "    sector_weights = calculate_sector_weights(df, weight_column_name)\n",
    "    return np.where(sector_weights == 0, 0, df[weight_column_name] / sector_weights)\n",
    "\n",
    "# Function to calculate an assets sector contribution\n",
    "def calculate_sector_contribution_return(asset_weights_in_sector, returns):\n",
    "    return asset_weights_in_sector * returns\n",
    "\n",
    "# Function to calculate daily sector return\n",
    "def calculate_total_sector_return(df, sector_contribution_column):\n",
    "    return df.groupby(['Date', 'GICS Sector'])[sector_contribution_column].transform('sum')\n",
    "\n",
    "# Function to calculate daily portfolio return\n",
    "def calculate_daily_total_return(df, total_sector_return_column):\n",
    "    return df.groupby('Date')[total_sector_return_column].transform('sum')\n",
    "\n",
    "\n",
    "# Function to apply all calculations to a DataFrame for given portfolio or benchmark columns\n",
    "def apply_calculations_to_df(df, weight_col, return_col, prefix):\n",
    "    df[f'{prefix} Weighted Return'] = calculate_weighted_returns(df[weight_col], df[return_col])\n",
    "    df[f'{prefix} Sector Weight'] = calculate_sector_weights(df, weight_col)\n",
    "    df[f'{prefix} Asset Weight in Sector'] = calculate_asset_weight_in_sector(df, weight_col)\n",
    "    sector_contribution_return = calculate_sector_contribution_return(df[f'{prefix} Asset Weight in Sector'], df[return_col])\n",
    "    df[f'{prefix} Sector Contribution Return'] = sector_contribution_return\n",
    "    total_sector_return = calculate_total_sector_return(df, f'{prefix} Sector Contribution Return')\n",
    "    df[f'{prefix} Daily Sector Return'] = total_sector_return\n",
    "    df[f'{prefix} Daily Total Return'] = calculate_daily_total_return(df, f'{prefix} Daily Sector Return')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the calculations to both portfolio and benchmark\n",
    "merged_data = apply_calculations_to_df(merged_data, 'Portfolio Weight', 'Return', 'Portfolio')\n",
    "merged_data = apply_calculations_to_df(merged_data, 'Benchmark Weight', 'Return', 'Benchmark')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribution calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_allocation_effect(df):\n",
    "    return (df['Portfolio Sector Weight'] - df['Benchmark Sector Weight']) * (df['Benchmark Daily Sector Return'] - df['Benchmark Daily Total Return'])\n",
    "\n",
    "def calculate_selection_effect(df):\n",
    "    return df['Benchmark Sector Weight'] * (df['Portfolio Daily Sector Return'] - df['Benchmark Daily Sector Return'])\n",
    "\n",
    "def calculate_interaction_effect(df):\n",
    "    return (df['Portfolio Sector Weight'] - df['Benchmark Sector Weight']) * (df['Portfolio Daily Sector Return'] - df['Benchmark Daily Sector Return'])\n",
    "\n",
    "def sum_of_effects(allocation, selection, interaction):\n",
    "    return allocation + selection + interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HE1\\AppData\\Local\\Temp\\ipykernel_1900\\4103802969.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  excess_test['Excess Return'] = excess_test['Portfolio Weighted Return'] - excess_test['Benchmark Weighted Return']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Excess Return</th>\n",
       "      <th>Sum Effects</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>-0.008123</td>\n",
       "      <td>-0.008123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-02</th>\n",
       "      <td>0.027996</td>\n",
       "      <td>0.027996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-03</th>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.013347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-04</th>\n",
       "      <td>-0.007270</td>\n",
       "      <td>-0.007270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-05</th>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-06</th>\n",
       "      <td>-0.005410</td>\n",
       "      <td>-0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07</th>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.008788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-08</th>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.006079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-09</th>\n",
       "      <td>-0.014300</td>\n",
       "      <td>-0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-10</th>\n",
       "      <td>-0.010830</td>\n",
       "      <td>-0.010830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-11</th>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.006022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-12</th>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.020310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-13</th>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.003049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-14</th>\n",
       "      <td>-0.016542</td>\n",
       "      <td>-0.016542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-15</th>\n",
       "      <td>0.009642</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-16</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-17</th>\n",
       "      <td>-0.005206</td>\n",
       "      <td>-0.005206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-18</th>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19</th>\n",
       "      <td>0.040683</td>\n",
       "      <td>0.040683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20</th>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.044698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Excess Return  Sum Effects\n",
       "Date                                  \n",
       "2023-09-01      -0.008123    -0.008123\n",
       "2023-09-02       0.027996     0.027996\n",
       "2023-09-03      -0.013347    -0.013347\n",
       "2023-09-04      -0.007270    -0.007270\n",
       "2023-09-05       0.000475     0.000475\n",
       "2023-09-06      -0.005410    -0.005410\n",
       "2023-09-07       0.008788     0.008788\n",
       "2023-09-08       0.006079     0.006079\n",
       "2023-09-09      -0.014300    -0.014300\n",
       "2023-09-10      -0.010830    -0.010830\n",
       "2023-09-11       0.006022     0.006022\n",
       "2023-09-12       0.020310     0.020310\n",
       "2023-09-13       0.003049     0.003049\n",
       "2023-09-14      -0.016542    -0.016542\n",
       "2023-09-15       0.009642     0.009642\n",
       "2023-09-16       0.000827     0.000827\n",
       "2023-09-17      -0.005206    -0.005206\n",
       "2023-09-18      -0.001254    -0.001254\n",
       "2023-09-19       0.040683     0.040683\n",
       "2023-09-20       0.044698     0.044698"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excess_test = merged_data[['Date', 'Portfolio Weighted Return', 'Benchmark Weighted Return']]\n",
    "excess_test['Excess Return'] = excess_test['Portfolio Weighted Return'] - excess_test['Benchmark Weighted Return']\n",
    "daily_excess_returns = excess_test[['Date', 'Excess Return']].groupby(['Date']).sum()\n",
    "\n",
    "allocation = calculate_allocation_effect(merged_data)\n",
    "selection = calculate_selection_effect(merged_data)\n",
    "interaction = calculate_interaction_effect(merged_data)\n",
    "sum_effects = sum_of_effects(allocation, selection, interaction)\n",
    "\n",
    "sum_effects.index = merged_data['Date']\n",
    "sum_effects.name = 'Sum Effects'  # Assign a name to the series\n",
    "daily_sum_of_attributions = sum_effects.drop_duplicates().groupby(['Date']).sum()\n",
    "\n",
    "# Merge the data and compare the results. They should be the same.\n",
    "testing_calculation_validity = pd.merge(daily_excess_returns, daily_sum_of_attributions, on='Date', how='inner')\n",
    "testing_calculation_validity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
